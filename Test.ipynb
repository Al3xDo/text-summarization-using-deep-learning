{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"mount_file_id":"1xlZUCTavajeeOy7VFaC8M6NYT1hSwpZU","authorship_tag":"ABX9TyOTF+cmOehDHxYuPxqfIVKR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xbqmolkhah3B","executionInfo":{"status":"ok","timestamp":1605157800439,"user_tz":-420,"elapsed":1027,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"6fe1c36d-5f8c-4916-e6e3-1ba7400e9c71","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd '/content/drive/My Drive'"],"execution_count":574,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c8kNGfbqWYFj","executionInfo":{"status":"ok","timestamp":1605157800945,"user_tz":-420,"elapsed":1521,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state\n","            inputs: (batchsize * 1 * de_in_dim)\n","            states: (batchsize * 1 * de_latent_dim)\n","            \"\"\"\n","\n","            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch size * en_seq_len * latent_dim\n","            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>', U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n","            if verbose:\n","                print('Ws+Uh>', Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","\n","            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        fake_state_c = K.sum(encoder_out_seq, axis=1)\n","        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":575,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcXHJAH5BT_c","executionInfo":{"status":"ok","timestamp":1605157800946,"user_tz":-420,"elapsed":1518,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n","                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n","                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n","                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n","                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n","                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n","                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n","                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n","                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n","                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n","                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n","                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n","                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n","                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n","                           \"you're\": \"you are\", \"you've\": \"you have\"}"],"execution_count":576,"outputs":[]},{"cell_type":"code","metadata":{"id":"x752qwe1PsaR","executionInfo":{"status":"ok","timestamp":1605157800946,"user_tz":-420,"elapsed":1512,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["max_text_len = 30\n","max_summary_len = 8"],"execution_count":577,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDKXPQJmOIlJ","executionInfo":{"status":"ok","timestamp":1605157800947,"user_tz":-420,"elapsed":1509,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["import numpy as np\n","import pandas as pd \n","from tensorflow import keras\n","import re\n","from bs4 import BeautifulSoup\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n","from tensorflow.keras.models import Model,Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","import warnings\n","pd.set_option(\"display.max_colwidth\", 200)\n","warnings.filterwarnings(\"ignore\")"],"execution_count":578,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8r3GV1OByLy","executionInfo":{"status":"ok","timestamp":1605157800948,"user_tz":-420,"elapsed":1505,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"8fc4e00e-f3bf-471e-d622-e8505c392476","colab":{"base_uri":"https://localhost:8080/"}},"source":["import nltk\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words('english')) \n","\n","def text_cleaner(text,num):\n","    newString = text.lower()\n","    newString = BeautifulSoup(newString, \"lxml\").text\n","    newString = re.sub(r'\\([^)]*\\)', '', newString)\n","    newString = re.sub('\"','', newString)\n","    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n","    newString = re.sub(r\"'s\\b\",\"\",newString)\n","    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n","    newString = re.sub('[m]{2,}', 'mm', newString)\n","    if(num==0):\n","        tokens = [w for w in newString.split() if not w in stop_words]\n","    else:\n","        tokens=newString.split()\n","    long_words=[]\n","    for i in tokens:\n","        if len(i)>1:                                                \n","            long_words.append(i)   \n","    return (\" \".join(long_words)).strip()"],"execution_count":579,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EEpPDMdT2lAX","executionInfo":{"status":"ok","timestamp":1605157800955,"user_tz":-420,"elapsed":1507,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":580,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEdpRYPdCXFT","executionInfo":{"status":"ok","timestamp":1605157800957,"user_tz":-420,"elapsed":1501,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","import pickle\n","\n","with open('/content/drive/My Drive/tokenizer.pickle', 'rb') as handle:\n","    x_tokenizer = pickle.load(handle)"],"execution_count":581,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAgvN8alOmep","executionInfo":{"status":"ok","timestamp":1605157800958,"user_tz":-420,"elapsed":1497,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["with open('/content/drive/My Drive/y_tokenizer.pickle', 'rb') as handle:\n","    y_tokenizer = pickle.load(handle)"],"execution_count":582,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t5hZ8cASJcV","executionInfo":{"status":"ok","timestamp":1605157802245,"user_tz":-420,"elapsed":2780,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["model = keras.models.load_model('/content/drive/My Drive/model_LSTM.h5',custom_objects={'AttentionLayer': AttentionLayer})"],"execution_count":583,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5LAG3NNtJGU","executionInfo":{"status":"ok","timestamp":1605157802246,"user_tz":-420,"elapsed":2777,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["from flask import Flask, redirect, url_for, render_template, request"],"execution_count":584,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XoqpYyENdHZ","executionInfo":{"status":"ok","timestamp":1605157805109,"user_tz":-420,"elapsed":5637,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"f2ad3512-aeca-4849-cd0c-afed27a9a76e","colab":{"base_uri":"https://localhost:8080/"}},"source":["s = input('enter text: ')"],"execution_count":585,"outputs":[{"output_type":"stream","text":["enter text: i always buy chips at Vinh's store because this store always try it best to make product\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bbHoLzUdCAd1","executionInfo":{"status":"ok","timestamp":1605157805110,"user_tz":-420,"elapsed":5633,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["cleaned_text = []\n","cleaned_text.append(text_cleaner(s,0)) "],"execution_count":586,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh5wU0S8OMqo","executionInfo":{"status":"ok","timestamp":1605157805110,"user_tz":-420,"elapsed":5629,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"ceef4014-218c-409c-ec5c-8b83a414e400","colab":{"base_uri":"https://localhost:8080/"}},"source":["cleaned_text"],"execution_count":587,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['always buy chips vinh store store always try best make product']"]},"metadata":{"tags":[]},"execution_count":587}]},{"cell_type":"code","metadata":{"id":"NrtGznnqQddt","executionInfo":{"status":"ok","timestamp":1605157805111,"user_tz":-420,"elapsed":5622,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["x = np.array(cleaned_text)"],"execution_count":588,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHKowOtcPfVr","executionInfo":{"status":"ok","timestamp":1605157805111,"user_tz":-420,"elapsed":5615,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["x_seq    =   x_tokenizer.texts_to_sequences(x) "],"execution_count":589,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6DbfMD8PiIv","executionInfo":{"status":"ok","timestamp":1605157805112,"user_tz":-420,"elapsed":5608,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["x   =   pad_sequences(x_seq,  maxlen=max_text_len, padding='post')"],"execution_count":590,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5ilM2e3NbUj","executionInfo":{"status":"ok","timestamp":1605157805112,"user_tz":-420,"elapsed":5600,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["reverse_target_word_index=y_tokenizer.index_word\n","reverse_source_word_index=x_tokenizer.index_word\n","target_word_index=y_tokenizer.word_index"],"execution_count":591,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJEgdSWLX4OX","executionInfo":{"status":"ok","timestamp":1605157805902,"user_tz":-420,"elapsed":6385,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"b0460b4a-2888-4274-9d15-7543b7916481","colab":{"base_uri":"https://localhost:8080/"}},"source":["encoder_model = keras.models.load_model('/content/drive/My Drive/encoder_model.h5')"],"execution_count":592,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HTPoy7AUZQLn","executionInfo":{"status":"ok","timestamp":1605157806406,"user_tz":-420,"elapsed":6882,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"5a5a892b-7ebc-4e14-a8c2-e4d917cea27a","colab":{"base_uri":"https://localhost:8080/"}},"source":["decoder_model = keras.models.load_model('/content/drive/My Drive/decoder_model.h5',custom_objects={'AttentionLayer': AttentionLayer})"],"execution_count":593,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"B2AEI695Mq6-","executionInfo":{"status":"ok","timestamp":1605157806407,"user_tz":-420,"elapsed":6877,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    e_out, e_h, e_c = encoder_model.predict(input_seq)\n","    \n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1,1))\n","    \n","    # Populate the first word of target sequence with the start word.\n","    target_seq[0, 0] = target_word_index['sostok']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","      \n","        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_token = reverse_target_word_index[sampled_token_index]\n","        \n","        if(sampled_token!='eostok'):\n","            decoded_sentence += ' '+sampled_token\n","\n","        # Exit condition: either hit max length or find stop word.\n","        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update internal states\n","        e_h, e_c = h, c\n","\n","    return decoded_sentence"],"execution_count":594,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2Pz1Y0GNSsl","executionInfo":{"status":"ok","timestamp":1605157806408,"user_tz":-420,"elapsed":6873,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}}},"source":["def seq2summary(input_seq):\n","    newString=''\n","    for i in input_seq:\n","        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n","            newString=newString+reverse_target_word_index[i]+' '\n","    return newString\n","\n","def seq2text(input_seq):\n","    newString=''\n","    for i in input_seq:\n","        if(i!=0):\n","            newString=newString+reverse_source_word_index[i]+' '\n","    return newString"],"execution_count":595,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjVriddkNMqL","executionInfo":{"status":"ok","timestamp":1605157807579,"user_tz":-420,"elapsed":8037,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"fcb00310-9311-4672-f8f4-dc9f4a97eaa7","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"Review:\",s)\n","print(\"Review:\",seq2text(x[0]))\n","print(\"Predicted summary:\",decode_sequence(x[0].reshape(1,max_text_len)))\n","print(\"\\n\")"],"execution_count":596,"outputs":[{"output_type":"stream","text":["Review: i always buy chips at Vinh's store because this store always try it best to make product\n","Review: always buy chips store store always try best make product \n","Predicted summary:  great chips\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jtu7XLZvVBJN","executionInfo":{"status":"ok","timestamp":1605157810336,"user_tz":-420,"elapsed":10789,"user":{"displayName":"Vinh Le","photoUrl":"","userId":"12955266199022363718"}},"outputId":"20738303-c680-4cc6-9ae7-e47ea08e44bb","colab":{"base_uri":"https://localhost:8080/"}},"source":["pip install gevent"],"execution_count":597,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (20.9.0)\n","Requirement already satisfied: zope.event in /usr/local/lib/python3.6/dist-packages (from gevent) (4.5.0)\n","Requirement already satisfied: greenlet>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent) (0.4.17)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from gevent) (50.3.2)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from gevent) (5.2.0)\n"],"name":"stdout"}]}]}